1. 上线导入URL脚本 @Done

    http://newicafe.baidu.com/issue/sspservice-1049/show?from=page

	0. ad_position_url 导入, 最后还是不折腾了， 到时候找OP给实体机器， 装个hadoop client 好了. 
	1. 修改配置
	shconf/common.conf
	+WUTAI_HADOOP_CLIENT=/home/work/local/wutai-hadoop-client/hadoop/bin/hadoop

	2. bash 写得心累。 帮忙看一下

	hadoop fs -ls /app/ecom/cm/online_dc/online/report/clb_realtime_5min_stat/clb_posid_url_output_5min/20161109/1430/

/home/work/local/wutai-hadoop-client/hadoop/bin/hadoop

[chenweidong@bjyz-sys-rpm0720160426104501-020.bjyz.baidu.com bin]$ ./hadoop fs -ls /
/bin/limit: relocation error: /lib/rh80/lib/i686/libc.so.6: symbol _dl_starting_up, version GLIBC_PRIVATE not defined in file ld-linux.so.2 with link time reference
[chenweidong@bjyz-sys-rpm0720160426104501-020.bjyz.baidu.com bin]$ pwd
/home/work/local/hadoop-client/hadoop/bin
[chenweidong@bjyz-sys-rpm0720160426104501-020.bjyz.baidu.com bin]$





	cp01-cb-web00.cp01.baidu.com

	wget  ftp://chenweidong:rdwork8888@cp01-sys-rath4-m52-2qa13.cp01.baidu.com:/devTools/wutai-hadoop-client.tar.gz


	wget ftp://chenweidong:rdwork8888@cp01-sys-rath4-m52-2qa13.cp01.baidu.com:/src/baidu/sspweb/datainf/iAdpositionUrl2.sh


	cp01-cb-web00.cp01.baidu.com
	cd /home/work/dataio/datainf/ && bash iAdpositionUrl2.sh 1>/dev/null 2>/dev/null


	[dataio]导入广告位url(数量不多无需处理)
	cd /home/work/dataio/datainf/ && bash iAdpositionUrl2.sh 1>/dev/null 2>/dev/null

	*/5 每5分钟

	cp01-cb-web00.cp01.baidu.com 这台机器

=======================================================

## 重新导入Hao123 计费名信息

	[chenweidong@cp01-sys-rath4-m52-2qa13.cp01.baidu.com migration]$ pwd
	/home/chenweidong/src/hao123support/migration
	ftp://10.95.112.177/python2.7.2.tar
	/home/chenweidong/devTools/python2.7.2/bin/python

		truncate hao123_tn;
		truncate hao123_tn_cpa;
		truncate hao123_account_group;

		mysql -uunion -h10.95.19.44 -P8920 -punion -Dunion4 < hao123_tn.sql
		mysql -uunion -h10.95.19.44 -P8920 -punion -Dunion4 < hao123_tn_cpa.sql
		mysql -uunion -h10.95.19.44 -P8920 -punion -Dunion4 < hao123_account_group.sql

2. 梳理Hao123 业务， 自测导出任务

重新搭建一个datahunter ** 


	1. tn 的重新导入任务 @mayongqiang  ** 
	2. search, cpa, ip   ** 
	3. juzi   ** 
	4. eHao123DictUcrm **
	   eHao123JuziReport  **
	   eHao123Tn2Ucrm  **
	   eHao123TnReport2Ucrm ** 


	1. export 2 palo

	http://gitlab.baidu.com/chenweidong/my-un-job/merge_requests/29/diffs

		1. 调整字段名称 xx_prorata -> xxx_divide
		2. make juzi work
		3. make eUcrm work

		juzi 产出的数据和旧的比对除了search 的尾数对不上(因为search_day_sttt目前尾数对不上)， 其他的都对上了。 

	@TODO
		0. 删除uc 前缀， 修改palo 表名
		1. cpa_report 导出更多的字段， 原始安装量， 修改cpa palo 表
		2. juzi_report 导出到palo， 建palo表
		3. 业务端报表展示 @yanghuabei 联调



http://gitlab.baidu.com/chenweidong/my-un-job/merge_requests/30

http://gitlab.baidu.com/mayongqiang/hao123support/merge_requests/3(这个我没权限合， 你帮忙合一下)
		0. 删除uc 前缀， 修改palo 表名
		1. cpa_report 导出更多的字段， 原始安装量， 修改cpa palo 表
		2. juzi_report 导出到palo， 建palo表


	@TODO
		3. 业务端报表展示 @yanghuabei 联调



	http://newicafe.baidu.com/issue/5178888/show?cid=5&spaceId=5021

## 数据库
```
计算库 
hao123_ip_day_sttt
hao123_cpa_day_sttt
hao123_search_day_sttt

palo 库
hao123_uccpa_report
hao123_ucip_report
hao123_ucsearch_report


http://gitlab.baidu.com/mayongqiang/hao123support/blob/master/docs/hao123_compute.sql
http://gitlab.baidu.com/mayongqiang/hao123support/blob/master/docs/hao123_palo.sql


=======sql temp bak
select customerid, get_time_on_doris(countdate), tname, biz, search, click, divide from hao123_search_day_sttt where countdate = '20160815'


select customerid, get_time_on_doris(countdate), `tname`, biz, ip, divide from hao123_ip_day_sttt where countdate = '20160815';

select customerid, get_time_on_doris(countdate), tname, biz, divide, install_v, active_v, retained_v, install_a, active_a, retained_a, install_p, active_p, retained_p from hao123_cpa_day_sttt where countdate ='20160814'

drop table hao123_cpa_day_sttt;
drop table hao123_ip_day_sttt;
drop table hao123_search_day_sttt;



## 自测方法
```
1. 在计算库里 hao123_xxxx_sttt 录入一条数据
2. 用conf-cwd 里面的配置
	## 把环境替换成局部的
    find . -regex '.*.sh' | xargs sed -i "s/source\ \/home\/work\/datainf\/conf/source\ \/home\/chenweidong\/src\/un-job\/shell\/datainf\/conf-cwd/g"
    ## 把环境替换回来
    find . -regex '.*.sh' | xargs sed -i "s/source\ \/home\/chenweidong\/src\/un-job\/shell\/datainf\/conf-cwd/source\ \/home\/work\/datainf\/conf/g"

3. 分别执行 e_hao123_xxx_report.sh 导入Palo 库




```

## 导出脚本
```
	shell/datainf/bin/export/palo/
		e_hao123_cpa_report.sh
		e_hao123_ip_report.sh
		e_hao123_search_report.sh 
```

## 配置
```
	shell/datainf/conf-cwd/palo/table_conf.sh

hao123_search_report="customerid,countdate,tname,biz_type,search,click,divide"
hao123_ip_report="customerid,countdate,tname,biz_type,ip,divide"
hao123_cpa_report="customerid,countdate,tname,biz_type,divide,install_v,active_v,retained_v,install_a,active_a,retained_a,install_p,active_p,retained_p"

```



=====================================


CREATE TABLE hao123_cpa_report (
  customerid largeint(40) NOT NULL COMMENT '所属用户',
  countdate int(11) NOT NULL COMMENT '日期',
  tname varchar(45) NOT NULL  COMMENT '计费名',
  biz_type int(10) NOT NULL  COMMENT '业务类型（设首、快捷、跳转）',
  divide double SUM NOT NULL COMMENT '分成',
  install_v bigint(20) SUM NOT NULL COMMENT '原始安装量',
  active_v bigint(20) SUM NOT NULL COMMENT '原始激活量',
  retained_v bigint(20) SUM NOT NULL COMMENT '原始留存量',
  install_a bigint(20) SUM NOT NULL  COMMENT '结算安装量',
  active_a bigint(20) SUM NOT NULL COMMENT '结算激活量',
  retained_a bigint(20) SUM NOT NULL COMMENT '结算留存量',
  install_p bigint(20) SUM NOT NULL COMMENT '安装收入',
  active_p bigint(20) SUM NOT NULL COMMENT '激活收入',
  retained_p bigint(20) SUM NOT NULL COMMENT '留存收入'
) ENGINE=OLAP
DISTRIBUTED BY HASH(customerid) BUCKETS 20
 PROPERTIES (
"storage_type" = "ROW"
);


CREATE TABLE `hao123_ip_report` (
  `customerid` largeint(40) NOT NULL COMMENT '渠道用户id',
  `countdate` int(11) NOT NULL COMMENT '日期',
  `tname` varchar(45) NOT NULL COMMENT'计费名',
  `biz_type` int(11) NOT NULL COMMENT '业务细分',
  `ip` bigint(20) SUM NOT NULL COMMENT '结算ip量',
  `divide` double SUM NOT NULL COMMENT '分成'
) ENGINE=OLAP
DISTRIBUTED BY HASH(`customerid`) BUCKETS 20
 PROPERTIES (
"storage_type" = "ROW"
);


CREATE TABLE `hao123_search_report` (
  `customerid` largeint(40) NOT NULL COMMENT '渠道用户id',
  `countdate` int(10) NOT NULL COMMENT '日期',
  `tname` varchar(45) NOT NULL COMMENT '计费名',
  `biz_type` int(11) NOT NULL COMMENT '业务细分',
  `search` bigint(20) SUM NOT NULL COMMENT '滤后搜索pv',
  `click` bigint(20) SUM NOT NULL COMMENT '点击量',
  `divide` double SUM NOT NULL COMMENT '分成'
) ENGINE=OLAP
DISTRIBUTED BY HASH(`customerid`) BUCKETS 20
 PROPERTIES (
"storage_type" = "ROW"
);

drop table hao123_juzi_report_t1;


CREATE TABLE `hao123_juzi_report` (
  `customerid` largeint(40) NOT NULL COMMENT '用户id',
  `countdate` int(10) NOT NULL COMMENT '日期',
  `tname` varchar(45) NOT NULL COMMENT '计费名',
  `biz_type` int(11) NOT NULL COMMENT '业务类型',
  `pv` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'pv',
  `uv` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'uv',
  `ip` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'ip',
  `join_uv` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '去重uv',
  `search_uv` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '滤前搜索uv',
  `search_uv_filter` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '滤后搜索Uv',
  `search_pv` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '滤前搜索pv',
  `search_pv_filter` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '滤后搜索pv',
  `ps_consum` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '总消费量', 
  `ip_divide` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'IP分成', 
  `cpa_divide` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'CPA分成', 
  `search_divide` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '检索分成', 
  `ss_search` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'ss滤后搜索PV', 
  `dz_search` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'dz滤后搜索PV', 
  `ss_click` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'ss点击量', 
  `dz_click` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'dz点击量', 
  `ss_consum` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'ss消费量', 
  `dz_consum` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'dz消费量', 
  `pg_click` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'pg点击量', 
  `pg_consum` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT 'pg消费量', 
  `active_a` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '结算激活量', 
  `install_a` bigint(20) SUM NOT NULL DEFAULT "0" COMMENT '结算安装量'
) ENGINE=OLAP
DISTRIBUTED BY HASH(`customerid`) BUCKETS 20
 PROPERTIES (
"storage_type" = "ROW"
);








2. UCRM 

http://newicafe.baidu.com/issue/unionagile-654/show?from=page

UCRM 
文件1: 计费名维度流量明细
文件2: 桔子浏览器流量明细
文件3: 计费名信息
的导出

其中里面juzi_report 的依赖的数据还比较多， 还依赖cpa_day。 我看还是按照我们其他迁移任务的做法， 再写一个导入数据入库的任务吧。 


文件1: 计费名维度流量明细

	from: hao123_tn_report
	日期  countdate
	会员名id user_id
	会员计费名id tname? @TODO id?
	PV  pv
	UV uv
	IP ip
	去重UV  join_uv
	滤前搜索UV search_uv
	滤后搜索UV search_uv_filter
	滤前搜索PV search_pv
	滤后搜索PV search_pv_filter
	搜索量-滤后修正后?   @TODO
	点击量 ps_click 
	消费量 ps_consum
	现金消费量 cash_consum
	预计分成 divide @ToConfirm

	====
		@ToConfrim
		1. 会员计费名id?
		2. 搜索量-滤后修正后? 

文件2: 桔子浏览器流量明细
	juzi_report 的相关导入任务需要迁移
	lib/Union/Cpa/Juzireport.php

	from: hao123_union
	juzi_report

	日期 count_date
	会员名id ucid
	计费名id @TODO
	结算安装量 install_a
	结算激活量 active_a
	总消费量 ps_consum
	CPA分成 cpa_proprata
	IP分成   ip_prorata
	检索分成 search_prorata
	haoIP ip
	haoPV pv
	haoUV uv
	hao去重uv  join_uv
	滤前搜索PV  search_pv
	滤后搜索PV  search_pv_filter
	滤前搜索UV  search_uv
	滤后搜索UV  search_uv_filter
	pg点击量  pg_click
	pg消费量 pg_consum
	ss搜索量 ss_search
	ss点击量 ss_click
	ss消费量 ss_consum
	dz 搜索量 dz_search
	dz 点击量 dz_click
	dz 消费量 dz_consum


	=====
		@ToConfirm 
		1. 计费名id @TODO
		2. 计费名名字 @ToConfirm tname
		3. 预估tac%  @TODO 

drop table if exists hao123_juzi_day_sttt;
CREATE TABLE `hao123_juzi_day_sttt` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tname` varchar(45) COLLATE utf8_bin NOT NULL DEFAULT '',
  `customerid` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '渠道用户id',
  `account_type` int(10) NOT NULL DEFAULT '0' COMMENT '结算类型(千次IP,自然检索)',
  `biz_type` int(10) NOT NULL DEFAULT '0' COMMENT '业务类型（设首、快捷、跳转）',
  `countdate` int(11) NOT NULL DEFAULT '0',
  `pv` bigint(20) NOT NULL DEFAULT '0',
  `uv` bigint(20) NOT NULL DEFAULT '0',
  `ip` bigint(20) NOT NULL DEFAULT '0',
  `join_uv` bigint(20) NOT NULL DEFAULT '0' COMMENT '去重uv',
  `search_uv` bigint(20) NOT NULL DEFAULT '0' COMMENT '滤前搜索uv',
  `search_uv_filter` bigint(20) NOT NULL DEFAULT '0' COMMENT '滤后搜索Uv',
  `search_pv` bigint(20) NOT NULL DEFAULT '0' COMMENT '滤前搜索pv',
  `search_pv_filter` bigint(20) DEFAULT '0' COMMENT '滤后搜索pv',
  `ps_consum` bigint(20) NOT NULL DEFAULT '0' COMMENT '总消费量',
  `ip_divide` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT 'IP分成',
  `cpa_divide` bigint(20) NOT NULL DEFAULT '0' COMMENT 'CPA分成',
  `search_divide` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT '检索分成',
  `ss_search` bigint(20) NOT NULL DEFAULT '0' COMMENT 'ss滤后搜索PV',
  `dz_search` bigint(20) NOT NULL DEFAULT '0' COMMENT 'dz滤后搜索PV',
  `ss_click` bigint(20) NOT NULL DEFAULT '0' COMMENT 'ss点击量',
  `dz_click` bigint(20) NOT NULL DEFAULT '0' COMMENT 'dz点击量',
  `ss_consum` bigint(20) NOT NULL DEFAULT '0' COMMENT 'ss消费量',
  `dz_consum` bigint(20) NOT NULL DEFAULT '0' COMMENT 'dz消费量',
  `pg_click` bigint(20) NOT NULL DEFAULT '0' COMMENT 'pg点击量',
  `pg_consum` bigint(20) NOT NULL DEFAULT '0' COMMENT 'pg消费量',
  `active_a` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT '结算激活量',
  `install_a` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT '结算安装量',
  PRIMARY KEY (`id`),
  UNIQUE KEY `tname` (`tname`,`countdate`),
  KEY `ucid` (`countdate`,`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=539302 DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='桔子浏览器';


ip_prorata, cpa_prorata, search_prorata, active_a, install_a




10000001_hao_ws

juzi_report

hao123_tn_bdid
hao123_tn_pv
hao123_tn_clientIp
hao123_join_index_uv
udw_all_tn_filter_pv
udw_all_tn_unfilter_pv
hao123_all_uv_filterNo_tn
hao123_all_uv_filterYes_tn
union_mate_cost_filter 



这变导入数据的方式有点暴力， 任务开始的时候导入到一个内存里的Array
我觉得我们还是的类似Hao123 的 Origin_table 搞一个。 如果有效率问题的话？
这个依赖的文件有点多。 不同地方的导入到数据到内存也有些重复代码





文件3: 计费名信息

	from: hao123_tn

	会员名id user_id
	计费名id 
	计费名名称 tname ? @TODO id?
	结算方式 account_type
	业务属性 biz_attr 
	业务类型 biz_type
	计算类型 compute_type 
	基础单价 base_price
	调整比例 rate
	计费类型 account_type
	计费二级类型  @TODO 


	@ToConfirm 
		1. Hao123_tn_cpa？ 这个cpa 的计费方式不考虑？ 
		2. 计费名id tname ? @TODO id?
		3. 计费二级类型  @TODO  Hao123   @Chenxueya 是我们根据union的逻辑，增加的字段，hao123没有

		http://wiki.baidu.com/pages/viewpage.action?pageId=152119949 导出到UCRM 的数据接口 
		这个Story 导出的要只包括hao123 的计费名？ 计费名二级类型固定是 Hao123 






文件4: 字典表

from 【UCRM&Union】hao123接口沟通 聊天记录


  1 - 计费类型
  		1 － 搜索推广合作
  2 - 计费名二级类型
  		1 -  Hao123
  3 - 业务属性
  		1 － 软件
  		2 － 网址站
  4 － 业务类型
  		1 -  hao123 桌面快捷
  		2 -  hao123 设首
  		3 -  hao123 跳转
  		4 -  WIFI 起始页
  		5 -  广告推广
  		6 -  百度卫士
  		7 -  百度浏览器内置hao123
  		8 -  桔子浏览器
  		9 -  第三方浏览器内置hao123
  5 - 浏览器类型
  		1 - 桔子
  6 - 结算方式
  		1 - 不分帐
  		2 - 千次IP
  		3 - 千次UV 
  		4 - 自然检索
  		5 - CPA
  7 - 计算类型
  		1 － 固定
  		2 － 阶梯 



create table `ucrm_hao123_dict` (
	`id` bigint(20) not null auto_increment comment '自增主键',
	`dict_type` bigint(20) not null comment '字典类型',
	`dict_id` bigint(20) not null comment '字典id',
	`dict_name` varchar(255) not null comment '字典名称',
	primary key(id)
);



INSERT INTO `ucrm_hao123_dict` (`id`, `dict_type`, `dict_id`, `dict_name`)
VALUES
	(1, 1, 1, '搜索推广合作'),
	(2, 2, 1, 'Hao123'),
	(3, 3, 1, '软件'),
	(4, 3, 2, '网址站'),
	(5, 4, 1, 'hao123 桌面快捷'),
	(6, 4, 2, 'hao123 设首'),
	(7, 4, 3, 'hao123 跳转'),
	(8, 4, 4, 'WIFI 起始页'),
	(9, 4, 5, '广告推广'),
	(10, 4, 6, '百度卫士'),
	(11, 4, 7, '百度浏览器内置 hao123'),
	(12, 4, 8, '桔子浏览器'),
	(13, 4, 9, '第三方浏览器内置hao123'),
	(14, 5, 1, '桔子'),
	(15, 6, 1, '不分帐'),
	(16, 6, 2, '千次IP'),
	(17, 6, 3, '千次UV'),
	(18, 6, 4, '自然检索'),
	(19, 6, 5, 'CPA'),
	(20, 7, 1, '固定'),
	(21, 7, 2, '阶梯');



CREATE TABLE `search_day` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `day` int(10) unsigned NOT NULL,
  `tn` varchar(45) COLLATE utf8_bin NOT NULL,
  `ucid` bigint(20) unsigned NOT NULL COMMENT '所属用户',
  `rate` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '调整比例',
  `biz_id` int(10) unsigned NOT NULL COMMENT '业务类型',
  `ps_search_filter` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT '检索量',
  `ps_click` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT '点击量',
  `ps_consum` bigint(20) unsigned NOT NULL DEFAULT '0' COMMENT '点击消费',
  `prorata` bigint(20) unsigned NOT NULL DEFAULT '0',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `industry_rate` int(11) NOT NULL DEFAULT '100',
  `compute_id` int(10) unsigned NOT NULL DEFAULT '0',
  `ag_id` int(11) unsigned NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  UNIQUE KEY `tn_day_UNIQUE` (`tn`,`day`),
  KEY `day` (`day`),
  KEY `ag_id_day` (`ag_id`,`day`)
) ENGINE=InnoDB AUTO_INCREMENT=24665821 DEFAULT CHARSET=utf8 COLLATE=utf8_bin ROW_FORMAT=COMPACT;

day	sum(ps_search_filter)	sum(ps_click)	sum(ps_consum)	sum(prorata)
20161113	30392926	685592	188239521	49410800




day	sum(ps_search_filter)	sum(ps_click)	sum(ps_consum)	sum(prorata)
20161107	36634226	966538	277776027	73480202
20161108	35709077	922972	269379838	71052205
20161109	34660701	917678	268055871	70975872
20161110	33608751	947528	285433360	75022120
20161111	32389622	967392	303644148	78652170
20161112	30830476	725608	201864853	52862824
20161113	30392926	685592	188239521	49410800



INSERT INTO `hao123_search_day_sttt` (`id`, `tname`, `countdate`, `customerid`, `compute_type`, `biz_type`, `ag_id`, `rate`, `search`, `click`, `income`, `divide`, `industry_rate`)
VALUES
	(1, X'73756D5F666F725F74657374', 20161107, 0, 0, 0, 0, 0, 36634226, 0, 277776027, 0, 100);
INSERT INTO `hao123_search_day_sttt` (`id`, `tname`, `countdate`, `customerid`, `compute_type`, `biz_type`, `ag_id`, `rate`, `search`, `click`, `income`, `divide`, `industry_rate`)
VALUES
	(2, X'73756D5F666F725F74657374', 20161108, 0, 0, 0, 0, 0, 35709077, 0, 269379838, 0, 100);
INSERT INTO `hao123_search_day_sttt` (`id`, `tname`, `countdate`, `customerid`, `compute_type`, `biz_type`, `ag_id`, `rate`, `search`, `click`, `income`, `divide`, `industry_rate`)
VALUES
	(3, X'73756D5F666F725F74657374', 20161109, 0, 0, 0, 0, 0, 34660701, 0, 268055871, 0, 100);
INSERT INTO `hao123_search_day_sttt` (`id`, `tname`, `countdate`, `customerid`, `compute_type`, `biz_type`, `ag_id`, `rate`, `search`, `click`, `income`, `divide`, `industry_rate`)
VALUES
	(4, X'73756D5F666F725F74657374', 20161110, 0, 0, 0, 0, 0, 33608751, 0, 285433360, 0, 100);
INSERT INTO `hao123_search_day_sttt` (`id`, `tname`, `countdate`, `customerid`, `compute_type`, `biz_type`, `ag_id`, `rate`, `search`, `click`, `income`, `divide`, `industry_rate`)
VALUES
	(5, X'73756D5F666F725F74657374', 20161111, 0, 0, 0, 0, 0, 32389622, 0, 303644148, 0, 100);
INSERT INTO `hao123_search_day_sttt` (`id`, `tname`, `countdate`, `customerid`, `compute_type`, `biz_type`, `ag_id`, `rate`, `search`, `click`, `income`, `divide`, `industry_rate`)
VALUES
	(6, X'73756D5F666F725F74657374', 20161112, 0, 0, 0, 0, 0, 30830476, 0, 188239521, 0, 100);




